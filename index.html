<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Zhangjie Wu </title> <meta name="author" content="Jay Zhangjie Wu"> <meta name="description" content="Zhangjie Wu's homepage. "> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://zhangjiewu.github.io/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> </head> <body class="fixed-top-nav sticky-bottom-footer"> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Zhangjie Wu</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/"> <span class="sr-only">(current)</span> </a> </li> <div class="navbar-brand social"> <a href="mailto:%6A%61%79.%7A%68%61%6E%67%6A%69%65.%77%75@%67%6D%61%69%6C.%63%6F%6D" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=WVp4yjoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/zhangjiewu" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/jay-zhangjie-wu-86460419b" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/jayzhangjiewu" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-twitter"></i></a> </div> </ul> </div> </div> </nav> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"></h1> <p class="desc"></p> </header> <article> <div class="profile float-left"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/jay-480.webp 480w,/assets/img/jay-800.webp 800w,/assets/img/jay-1400.webp 1400w," sizes="(min-width: 800px) 231.0px, (min-width: 576px) 30vw, 95vw" type="image/webp"> <img src="/assets/img/jay.png?c49e37f07f4f96888bb2167fff05ae3f" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="jay.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> <div class="more-info"></div> </div> <div class="clearfix"> <p>I am a Ph.D. student at <a href="https://sites.google.com/view/showlab/home?authuser=0" rel="external nofollow noopener" target="_blank">Show Lab</a>, <a href="https://www.nus.edu.sg/" rel="external nofollow noopener" target="_blank">National University of Singapore</a>, advised by <a href="https://sites.google.com/view/showlab" rel="external nofollow noopener" target="_blank">Prof. Mike Zheng Shou</a> and <a href="https://www.comp.nus.edu.sg/~whsu/" rel="external nofollow noopener" target="_blank">Prof. Wynne Hsu</a>. Previously, I received my B.Eng. in Computer Science from <a href="http://hc.buaa.edu.cn/" rel="external nofollow noopener" target="_blank">Shen Yuan Honors College</a> of <a href="https://buaa.edu.cn/" rel="external nofollow noopener" target="_blank">Beihang University</a>.</p> <p>My research focuses on AI for video understanding and generation.</p> <p><a href="mailto:jay.zhangjie.wu@gmail.com" title="email">email</a>: jay.zhangjie.wu [at] gmail.com</p> <p><a href="https://scholar.google.com/citations?user=WVp4yjoAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank">google scholar</a> · <a href="https://zhangjiewu.github.io/" title="GitHub">github</a> · <a href="https://www.linkedin.com/in/jay-zhangjie-wu-86460419b/" title="LinkedIn" rel="external nofollow noopener" target="_blank">linkedin</a> · <a href="https://twitter.com/jayzhangjiewu" title="X" rel="external nofollow noopener" target="_blank">twitter</a></p> </div> <hr> <h2> <a style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 15%">Feb 2024</th> <td> Tutorial <a href="https://showlab.github.io/cvpr2024-tutorial-video-diffusion-models/" rel="external nofollow noopener" target="_blank">Diffusion-based Video Generative Models</a> to appear at CVPR 2024. </td> </tr> <tr> <th scope="row" style="width: 15%">Oct 2023</th> <td> Code and model weights of <a href="https://showlab.github.io/Show-1/" rel="external nofollow noopener" target="_blank">Show-1</a> <a href="https://github.com/showlab/Show-1" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/github/stars/showlab/Show-1?style=social" alt=""></a> are released! </td> </tr> <tr> <th scope="row" style="width: 15%">May 2023</th> <td> Organized <a href="https://sites.google.com/view/loveucvpr23/track4" rel="external nofollow noopener" target="_blank">LOVEU-TGVE</a> (Text-Guided Video Editing) competition at CVPR 2023. </td> </tr> <tr> <th scope="row" style="width: 15%">Apr 2023</th> <td> Searching for papers on video diffusion models? Check out our GitHub repo <a href="https://github.com/showlab/Awesome-Video-Diffusion" rel="external nofollow noopener" target="_blank">Awesome-Video-Diffusion</a> <a href="https://github.com/showlab/Awesome-Video-Diffusion" rel="external nofollow noopener" target="_blank"><img src="https://img.shields.io/github/stars/showlab/Awesome-Video-Diffusion?style=social" alt=""></a>. </td> </tr> </table> </div> </div> <hr> <h2> <a style="color: inherit">publications</a> </h2> <a>(*) denotes equal contribution</a> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/videoswap-480.webp 480w,/assets/img/publication_preview/videoswap-800.webp 800w,/assets/img/publication_preview/videoswap-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/videoswap.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="videoswap.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gu2023videoswap" class="col-sm-9"> <div class="title">VideoSwap: Customized Video Subject Swapping with Interactive Semantic Point Correspondence</div> <div class="author"> Yuchao Gu, Yipin Zhou, Bichen Wu, Licheng Yu, Jia-Wei Liu, Rui Zhao, <em>Jay Zhangjie Wu</em>, David Junhao Zhang, Mike Zheng Shou, and Kevin Tang </div> <div class="periodical"> CVPR 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2312.02087" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/showlab/VideoSwap" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://videoswap.github.io/" rel="external nofollow noopener" target="_blank">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/dynvideoe-480.webp 480w,/assets/img/publication_preview/dynvideoe-800.webp 800w,/assets/img/publication_preview/dynvideoe-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/dynvideoe.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="dynvideoe.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="liu2023dynvideo" class="col-sm-9"> <div class="title">DynVideo-E: Harnessing Dynamic NeRF for Large-Scale Motion- and View-Change Human-Centric Video Editing</div> <div class="author"> Jia-Wei Liu, Yan-Pei Cao, <em>Jay Zhangjie Wu</em>, Weijia Mao, Yuchao Gu, Rui Zhao, Jussi Keppo, Ying Shan, and Mike Zheng Shou </div> <div class="periodical"> CVPR 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2310.10624" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://showlab.github.io/DynVideo-E/" rel="external nofollow noopener" target="_blank">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/motiondirector-480.webp 480w,/assets/img/publication_preview/motiondirector-800.webp 800w,/assets/img/publication_preview/motiondirector-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/motiondirector.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="motiondirector.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhao2023motiondirector" class="col-sm-9"> <div class="title">MotionDirector: Motion Customization of Text-to-Video Diffusion Models</div> <div class="author"> Rui Zhao, Yuchao Gu, <em>Jay Zhangjie Wu</em>, David Junhao Zhang, Jiawei Liu, Weijia Wu, Jussi Keppo, and Mike Zheng Shou </div> <div class="periodical"> arXiv 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2310.08465" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/showlab/MotionDirector" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://showlab.github.io/MotionDirector/" rel="external nofollow noopener" target="_blank">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/show1-480.webp 480w,/assets/img/publication_preview/show1-800.webp 800w,/assets/img/publication_preview/show1-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/show1.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="show1.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="zhang2023show" class="col-sm-9"> <div class="title">Show-1: Marrying pixel and latent diffusion models for text-to-video generation</div> <div class="author"> David Junhao Zhang*, <em>Jay Zhangjie Wu*</em>, Jia-Wei Liu*, Rui Zhao, Lingmin Ran, Yuchao Gu, Difei Gao, and Mike Zheng Shou </div> <div class="periodical"> arXiv 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2309.15818" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/showlab/Show-1" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://showlab.github.io/Show-1/" rel="external nofollow noopener" target="_blank">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/mixofshow-480.webp 480w,/assets/img/publication_preview/mixofshow-800.webp 800w,/assets/img/publication_preview/mixofshow-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/mixofshow.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="mixofshow.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="gu2024mix" class="col-sm-9"> <div class="title">Mix-of-show: Decentralized low-rank adaptation for multi-concept customization of diffusion models</div> <div class="author"> Yuchao Gu, Xintao Wang, <em>Jay Zhangjie Wu</em>, Yujun Shi, Yunpeng Chen, Zihan Fan, Wuyou Xiao, Rui Zhao, Shuning Chang, Weijia Wu, Yixiao Ge, Ying Shan, and Mike Zheng Shou </div> <div class="periodical"> NeurIPS 2024 </div> <div class="links"> <a href="http://arxiv.org/abs/2305.18292" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/TencentARC/Mix-of-Show" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://showlab.github.io/Mix-of-Show/" rel="external nofollow noopener" target="_blank">Project Page</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/tuneavideo-480.webp 480w,/assets/img/publication_preview/tuneavideo-800.webp 800w,/assets/img/publication_preview/tuneavideo-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/tuneavideo.gif" class="preview z-depth-1 rounded" width="100%" height="auto" alt="tuneavideo.gif" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wu2023tune" class="col-sm-9"> <div class="title">Tune-A-Video: One-Shot Tuning of Image Diffusion Models for Text-to-Video Generation</div> <div class="author"> <em>Jay Zhangjie Wu</em>, Yixiao Ge, Xintao Wang, Stan Weixian Lei, Yuchao Gu, Yufei Shi, Wynne Hsu, Ying Shan, Xiaohu Qie, and Mike Zheng Shou </div> <div class="periodical"> ICCV 2023 <a class="periodical"> · <b>4k+ Github Stars 🌟</b> </a> </div> <div class="links"> <a href="http://arxiv.org/abs/2212.11565" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/showlab/Tune-A-Video" rel="external nofollow noopener" target="_blank">Code</a> <a href="https://tuneavideo.github.io/" rel="external nofollow noopener" target="_blank">Project Page</a> <a href="https://colab.research.google.com/github/showlab/Tune-A-Video/blob/main/notebooks/Tune-A-Video.ipynb" rel="external nofollow noopener" target="_blank">Demo</a> <a href="https://www.youtube.com/watch?v=uzF6CTtjn-g" rel="external nofollow noopener" target="_blank">Two Minute Papers</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/leocod-480.webp 480w,/assets/img/publication_preview/leocod-800.webp 800w,/assets/img/publication_preview/leocod-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/leocod.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="leocod.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wu2023label" class="col-sm-9"> <div class="title">Label-Efficient Online Continual Object Detection in Streaming Video</div> <div class="author"> <em>Jay Zhangjie Wu</em>, David Junhao Zhang, Wynne Hsu, Mengmi Zhang, and Mike Zheng Shou </div> <div class="periodical"> ICCV 2023 </div> <div class="links"> <a href="http://arxiv.org/abs/2212.11565" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/showlab/Efficient-CLS" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/clvqa-480.webp 480w,/assets/img/publication_preview/clvqa-800.webp 800w,/assets/img/publication_preview/clvqa-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/clvqa.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="clvqa.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="lei2023symbolic" class="col-sm-9"> <div class="title">Symbolic Replay: Scene Graph as Prompt for Continual Learning on VQA Task</div> <div class="author"> Stan Weixian Lei*, Difei Gao*, <em>Jay Zhangjie Wu</em>, Yuxuan Wang, Wei Liu, Mengmi Zhang, and Mike Zheng Shou </div> <div class="periodical"> AAAI 2023 (Oral) </div> <div class="links"> <a href="http://arxiv.org/abs/2208.12037" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/showlab/CLVQA" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/egfr-480.webp 480w,/assets/img/publication_preview/egfr-800.webp 800w,/assets/img/publication_preview/egfr-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/egfr.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="egfr.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wang2022mining" class="col-sm-9"> <div class="title">Mining whole-lung information by artificial intelligence for predicting EGFR genotype and targeted therapy response in lung cancer: a multicohort study</div> <div class="author"> Shuo Wang*, He Yu*, Yuncui Gan*, <em>Zhangjie Wu</em>, and  others </div> <div class="periodical"> The Lancet Digital Health 2022 </div> <div class="links"> <a href="https://www.thelancet.com/journals/landig/article/PIIS2589-7500(22)00024-3/fulltext" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://www.thelancet.com/action/showPdf?pii=S2589-7500%2822%2900024-3" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col-sm-3 preview"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/publication_preview/opixray-480.webp 480w,/assets/img/publication_preview/opixray-800.webp 800w,/assets/img/publication_preview/opixray-1400.webp 1400w," sizes="200px" type="image/webp"> <img src="/assets/img/publication_preview/opixray.png" class="preview z-depth-1 rounded" width="100%" height="auto" alt="opixray.png" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div id="wei2020occluded" class="col-sm-9"> <div class="title">Occluded Prohibited Items Detection: An X-ray Security Inspection Benchmark and De-occlusion Attention Module</div> <div class="author"> Yanlu Wei*, Renshuai Tao*, <em>Zhangjie Wu</em>, Yuqing Ma, Libo Zhang, and Xianglong Liu </div> <div class="periodical"> ACM MM 2020 (Oral) </div> <div class="links"> <a href="http://arxiv.org/abs/2004.08656" rel="external nofollow noopener" target="_blank">Paper</a> <a href="https://github.com/OPIXray-author/OPIXray" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <footer class="sticky-bottom md-5" role="contentinfo"> <div class="container"> © Copyright 2024 Jay. Powered by <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?5d75c11f89cd96294bf5e6dd1ee1bb30"></script> <script defer src="/assets/js/common.js?fcfacfb8c6281f5e68d5a7d348186eb1"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=UA-111540567-4"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","UA-111540567-4");</script> </body> </html>